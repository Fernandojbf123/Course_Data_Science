{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bf2362",
   "metadata": {},
   "source": [
    "## Proyecto del Día 13 - Juego de Navegación en un Laberinto\n",
    "\n",
    "Este proyecto tiene como objetivo desarrollar un entorno de laberinto simple y aplicar un algoritmo de **Aprendizaje por Refuerzo** para enseñar a una IA a navegar desde un punto inicial hasta un objetivo.\n",
    "\n",
    "Dada la naturaleza de este proyecto, considero que el algoritmo más adecuado para este tipo de probleas es **Q-Learning**, por su facilidad de implelentación y comprensión, su estabilidad y su relación entre la exploración y la explotación.\n",
    "\n",
    "Por esa razón te propongo resolverlo usando ese algoritmo, aunque dejo a tu criterio si quieres resolverlo con otro algoritmo de tu elección. Siempre estaré a favor de que investigues, y expandas las habilidades propuestas por tu cuenta.\n",
    "\n",
    "### Descripción del Laberinto:\n",
    "\n",
    "El laberinto se representa como una matriz de dos dimensions, donde cada elemento puede ser:\n",
    "+ un camino libre (0)\n",
    "+ un obstáculo (1)\n",
    "+ el objetivo (G)\n",
    "\n",
    "La tarea es desarrollar un agente que pueda aprender a encontrar el camino desde un punto de inicio hasta el objetivo evitando obstáculos.\n",
    "\n",
    "\n",
    "### Creación del Laberinto\n",
    "\n",
    "Debido a que el desafío de hoy es bastante complejo, y que el objetivo final no se trata de que sepas desarrollar laberintos, sino sistemas para resolverlos, voy a facilitar la tarea entregando en este cuaderno el código para generar nuestros laberintos.\n",
    "\n",
    "Tu parte será la siguiente, que es diseñar y entrenar un modelo de Q-Learning para resolver el laberinto de la manera mpas eficiente, y luego mostrar una visualización sobre cómo lo ha hecho.\n",
    "\n",
    "Te deseo toda la suerte del mundo, y sobre todo, que te diviertas de a montones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "3e7ecc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías necesarias para todo el ejercicio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "6370346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear el laberinto\n",
    "def crear_laberinto(tamanio, porcentaje_paredes=20, inicio=(0, 0), meta=None):\n",
    "    laberinto = np.zeros((tamanio, tamanio))\n",
    "    numero_paredes = int((tamanio * tamanio) * porcentaje_paredes / 100)\n",
    "    \n",
    "    # Ubicar paredes\n",
    "    for pared in range(numero_paredes):\n",
    "        x, y = random.randint(0, tamanio-1), random.randint(0, tamanio-1)\n",
    "        \n",
    "        # Cuidar que inicio y meta no sean paredes\n",
    "        if (x, y) != inicio and (meta is None or (x, y) != meta):\n",
    "            laberinto[x, y] = 1\n",
    "            \n",
    "    # Ubicar la meta\n",
    "    if meta:\n",
    "        laberinto[meta] = 9  # Representa la meta con 9\n",
    "    else:\n",
    "        # Ubicar la meta aleatoriamente si no está especificado\n",
    "        while True:\n",
    "            x, y = random.randint(0, tamanio-1), random.randint(0, tamanio-1)\n",
    "            if laberinto[x, y] == 0 and (x, y) != inicio:\n",
    "                laberinto[x, y] = 9\n",
    "                break\n",
    "    \n",
    "    return laberinto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "6c648cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para visualizar el laberinto\n",
    "def ver_laberinto(laberinto):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(laberinto, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "10e052cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo de crear y mostrar laberintos\n",
    "laberinto = crear_laberinto(10, 20, inicio=(0, 0), meta=(9, 9))\n",
    "ver_laberinto(laberinto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f986ed5",
   "metadata": {},
   "source": [
    "### Ahora te toca a ti\n",
    "\n",
    "Lo que sigue es implementar todo el código para que un algoritmo de Q-Learning encuentre la manera más eficiente de llegar a la meta. Voy a dejarte los pasos que considero que son los necesarios para lograrlo\n",
    "\n",
    "##### 1. Parámetros para el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "234853df",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_times =500 # Times that leaning is repeated\n",
    "\n",
    "class MazeSolver:\n",
    "    \n",
    "    def __init__( self, maze=None, alpha=0.1, gamma=0.99, epsilon=0.2, initial_state=(0,0), obj_state=(0,0) ):        \n",
    "        # Dimensions (Based on the Maze data)\n",
    "        self.maze = maze\n",
    "        self.dimensions = maze.shape\n",
    "        \n",
    "        # States\n",
    "        self.initial_state = initial_state #index (i,j) in the laberinth\n",
    "        self.obj_state = obj_state #index (i,j) in the laberinth\n",
    "        self.state_num = self.dimensions[0]*self.dimensions[1] # for a 5,5 laberinth its 5x5 = 25\n",
    "        self.state = initial_state #current state (i,j) in the laberinth\n",
    "        self.s = 0 #index of the state (e.g. in a 5x5 laberinth (5,5) == 24)\n",
    "        self.next_state = (0,0) #next state (i,j) in the laberinth\n",
    "        self.next_s = 0 #index of the next state\n",
    "\n",
    "        # Learning conditions\n",
    "        self.alpha = alpha #learning ratio\n",
    "        self.gamma = gamma # discount factor\n",
    "        self.epsilon = epsilon #explore-exploit factor\n",
    "\n",
    "        # Actions\n",
    "        self.actions = ((-1,0),(1,0),(0,-1),(0,1))\n",
    "        self.actions_num = len(self.actions)\n",
    "        self.a = None #one of the four possible choises in a 2D laberinth\n",
    "        self.actions_sym = ['↑', '↓', '←', '→']\n",
    "\n",
    "        # Create Matrix Q(s,a)\n",
    "        self.Q = np.zeros((self.state_num,self.actions_num)) # Q(s,a)\n",
    "\n",
    "        # Ending condition\n",
    "        self.terminate = False\n",
    "        self.reward = 0\n",
    "    \n",
    "    \n",
    "    # State to index. This is s in the Matrix Q\n",
    "    def state_to_index(self,state):\n",
    "        self.s = self.state[0]*self.dimensions[1] + self.state[1]\n",
    "        return self.s\n",
    "\n",
    "    # Index to state. This is the state in the laberinth\n",
    "    def index_to_state(self,s):\n",
    "        i = s // self.dimensions[0]\n",
    "        j = s % self.dimensions[1]\n",
    "        self.state = [i,j]\n",
    "\n",
    "    def choose_action(self):               \n",
    "        #if explore - >\n",
    "        if np.random.rand(1)  < self.epsilon:\n",
    "            self.a = random.randint(0, self.actions_num - 1)\n",
    "        #Exploit (use the best action known in Q)\n",
    "        else:\n",
    "            self.a = np.argmax(Q[self.s,:])\n",
    "\n",
    "    def is_obstacle(self,state):\n",
    "        if self.maze[state] == 1:\n",
    "            return True\n",
    "    \n",
    "    def apply_action(self):\n",
    "        # Set new positions considering limits\n",
    "        # 1. up limit\n",
    "        if self.state[0] == 0 and self.a == 0:\n",
    "            next_state = self.state\n",
    "        # 2. down limit\n",
    "        elif self.state[0] == self.dimensions[0]-1 and self.a == 1:\n",
    "            next_state = self.state\n",
    "        # 3. left limit\n",
    "        elif self.state[1] == 0 and self.a == 2:\n",
    "            next_state = self.state\n",
    "        # 4. right limit\n",
    "        elif self.state[1] == self.dimensions[1]-1 and self.a == 3:\n",
    "            next_state = self.state\n",
    "        else:\n",
    "            next_state= tuple(np.add(self.state,self.actions[self.a]))\n",
    "\n",
    "        # set rewards or ending condition\n",
    "        terminate = False\n",
    "        if next_state == self.state and next_state != self.obj_state:\n",
    "            reward = -100\n",
    "        if next_state != self.state and not(self.is_obstacle(next_state)):\n",
    "            reward = -1\n",
    "        if self.is_obstacle(next_state): ## if is obstacle == True\n",
    "            reward = -100\n",
    "        if next_state == self.obj_state:\n",
    "            reward = 100\n",
    "            terminate = True\n",
    "\n",
    "        self.reward = reward\n",
    "        self.terminate = terminate\n",
    "        self.next_state = next_state\n",
    "        self.next_s = self.state_to_index(next_state)        \n",
    "\n",
    "    def update_Q_matrix(self):\n",
    "        self.Q[self.s,self.a] = self.Q[self.s,self.a] + self.alpha * (self.reward + self.gamma * np.max(self.Q[self.next_s]) - Q[self.s,self.a])\n",
    "\n",
    "    def update_state(self):\n",
    "        self.state = self.next_state\n",
    "        self.s = self.next_s\n",
    "\n",
    "    def restart(self):\n",
    "        # States\n",
    "        self.initial_state = (0,0) #index (i,j) in the laberinth\n",
    "        self.state = (0,0) #current state (i,j) in the laberinth\n",
    "        self.s = 0 #index of the state (e.g. in a 5x5 laberinth (5,5) == 24)\n",
    "        self.next_state = (0,0) #next state (i,j) in the laberinth\n",
    "        self.next_s = 0\n",
    "\n",
    "        # Actions\n",
    "        self.a = None #one of the four possible choises in a 2D laberinth\n",
    "        \n",
    "        # Ending condition\n",
    "        self.terminate = False\n",
    "        self.reward = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "10ad9d94-3d31-4407-82f0-b711d153b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = MazeSolver(maze=laberinto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125709aa",
   "metadata": {},
   "source": [
    "##### 2. Función para elegir acciones equilibrando entre explotación y exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "abbd3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(learning_times):\n",
    "    solver.restart()\n",
    "    \n",
    "    while not(solver.terminate):\n",
    "        solver.choose_action()\n",
    "        solver.apply_action()\n",
    "        solver.update_Q_matrix()\n",
    "        solver.update_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a6550",
   "metadata": {},
   "source": [
    "##### 3. Función para simular la acción en el laberinto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "f719b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.67417193e+08  3.31054107e+09  1.02286853e+09  2.76361590e+10]\n",
      " [ 5.31676360e+75  4.86685843e+75  8.11652475e+74  2.33364658e+75]\n",
      " [-3.48473316e+27 -2.49484500e+26 -1.54842147e+26 -2.09373593e+26]\n",
      " [-1.65675749e+25 -6.00605260e+23 -1.10024928e+24 -9.67759618e+23]\n",
      " [-2.41314954e+24 -1.71051860e+23 -1.78824263e+23 -2.13526815e+23]\n",
      " [-1.92257553e+24 -1.52896902e+23 -1.44492789e+23 -1.66907065e+23]\n",
      " [-2.80726638e+25 -1.96910976e+24 -1.60363511e+24 -1.48541564e+24]\n",
      " [-1.50226905e+23 -8.58489119e+21 -6.43964536e+21 -8.38407167e+21]\n",
      " [-1.40595321e+23 -8.64358650e+21 -6.83843833e+21 -7.69262805e+21]\n",
      " [-1.52904269e+23 -6.18307900e+21 -1.21212236e+22 -7.69347582e+21]\n",
      " [ 4.78431997e+11  2.52877565e+10  2.67397288e+10  1.49190326e+11]\n",
      " [-4.81995135e+06 -5.17842326e+06 -6.13110200e+05 -8.10099510e+05]\n",
      " [-2.27020500e+04 -5.15010000e+02 -6.54990000e+02 -6.35590000e+02]\n",
      " [-5.58980000e+02 -3.48600000e+01 -3.69700000e+01 -3.31600000e+01]\n",
      " [-5.33780000e+02 -5.36800000e+01 -5.59400000e+01 -3.72100000e+01]\n",
      " [-6.93448000e+03 -4.95900000e+01 -2.90200000e+01 -3.79380000e+02]\n",
      " [-4.91510000e+02 -3.38340000e+02 -2.71300000e+01 -3.72500000e+01]\n",
      " [-6.60639000e+03 -1.94400000e+01 -3.61500000e+02 -2.80300000e+01]\n",
      " [-3.91380000e+02 -2.58800000e+01 -2.89800000e+01 -2.10200000e+01]\n",
      " [-5.02510000e+02 -2.03000000e+01 -2.63200000e+01 -2.76600000e+02]\n",
      " [-9.02000000e+00 -1.00000000e-01 -8.00600000e+01 -6.30000000e-01]\n",
      " [-1.44216800e+04 -1.00118000e+03 -6.31360000e+02 -9.28450000e+02]\n",
      " [-1.98200000e+01 -1.47000000e+00 -4.60000000e-01 -4.50000000e-01]\n",
      " [-4.40000000e+00  0.00000000e+00 -1.00000000e-01 -2.00000000e-01]\n",
      " [-5.60000000e+00 -3.10000000e-01 -2.10000000e-01 -1.00000000e-01]\n",
      " [-4.19000000e+00 -4.60000000e-01 -5.70000000e-01 -7.00800000e+01]\n",
      " [-3.80000000e+02  0.00000000e+00  0.00000000e+00 -4.00000000e-01]\n",
      " [-3.40000000e+00 -6.00000000e+01  0.00000000e+00  0.00000000e+00]\n",
      " [-4.00000000e+00  0.00000000e+00  0.00000000e+00 -3.00000000e-01]\n",
      " [-3.92000000e+00 -2.10000000e-01 -1.00000000e-01 -3.00100000e+01]\n",
      " [-4.00000000e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-9.22000000e+00 -5.70000000e-01 -3.30000000e-01 -5.70000000e-01]\n",
      " [-1.43000000e+00 -2.00000000e+01 -1.00000000e-01 -2.00000000e+01]\n",
      " [-1.00000000e-01  0.00000000e+00  0.00000000e+00 -1.00000000e-01]\n",
      " [-3.00000000e-01 -1.00000000e-01  0.00000000e+00 -1.00000000e-01]\n",
      " [-4.00000000e-01  0.00000000e+00  0.00000000e+00 -1.00000000e-01]\n",
      " [-3.00000000e+01 -1.00000000e-01  0.00000000e+00  0.00000000e+00]\n",
      " [-4.00000000e-01 -1.00000000e-01 -1.00000000e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.00000000e-01  0.00000000e+00  0.00000000e+00 -1.00000000e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-5.00000000e-01 -3.00000000e-01  0.00000000e+00  0.00000000e+00]\n",
      " [-2.00000000e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.00000000e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.00000000e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-3.00000000e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(solver.Q,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3dc48",
   "metadata": {},
   "source": [
    "##### 4. Función principal para ejecutar el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5259c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bac97336",
   "metadata": {},
   "source": [
    "##### 5. Función para convertir coordenadas a índice lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5311d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f60f0d38",
   "metadata": {},
   "source": [
    "##### 6. Iniciar el laberinto y configurar el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355b8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addf32a0",
   "metadata": {},
   "source": [
    "##### 7. Función para mostrar el aprendizaje del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f818e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "060cb8db",
   "metadata": {},
   "source": [
    "##### 8. Visualizar el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f1228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
